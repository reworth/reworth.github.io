<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Reworth&#39;s Blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://reworth.site/"/>
  <updated>2018-01-26T03:16:15.123Z</updated>
  <id>http://reworth.site/</id>
  
  <author>
    <name>Reworth Yan</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>threading-lock</title>
    <link href="http://reworth.site/2018/01/26/threading-lock/"/>
    <id>http://reworth.site/2018/01/26/threading-lock/</id>
    <published>2018-01-26T03:14:54.000Z</published>
    <updated>2018-01-26T03:16:15.123Z</updated>
    
    <content type="html"><![CDATA[<h2 id="不使用lock的情况"><a href="#不使用lock的情况" class="headerlink" title="不使用lock的情况"></a>不使用lock的情况</h2><p>函数一：全局变量A的值每次加1，循环10次，并打印</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">def job1():</span><br><span class="line">    global A</span><br><span class="line">    for i in range(10):</span><br><span class="line">        A+=1</span><br><span class="line">        print(&apos;job1&apos;,A)</span><br></pre></td></tr></table></figure><p>函数二：全局变量A的值每次加10，循环10次，并打印</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">def job2():</span><br><span class="line">    global A</span><br><span class="line">    for i in range(10):</span><br><span class="line">        A+=10</span><br><span class="line">        print(&apos;job2&apos;,A)</span><br></pre></td></tr></table></figure><p>主函数：定义两个线程，分别执行函数一和函数二</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">if __name__== &apos;__main__&apos;:</span><br><span class="line">    A=0</span><br><span class="line">    t1=threading.Thread(target=job1)</span><br><span class="line">    t2=threading.Thread(target=job2)</span><br><span class="line">    t1.start()</span><br><span class="line">    t2.start()</span><br><span class="line">    t1.join()</span><br><span class="line">    t2.join()</span><br></pre></td></tr></table></figure><p>完整代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">import threading</span><br><span class="line"></span><br><span class="line">def job1():</span><br><span class="line">    global A</span><br><span class="line">    for i in range(10):</span><br><span class="line">        A+=1</span><br><span class="line">        print(&apos;job1&apos;,A)</span><br><span class="line"></span><br><span class="line">def job2():</span><br><span class="line">    global A</span><br><span class="line">    for i in range(10):</span><br><span class="line">        A+=10</span><br><span class="line">        print(&apos;job2&apos;,A)</span><br><span class="line"></span><br><span class="line">if __name__== &apos;__main__&apos;:</span><br><span class="line">    lock=threading.Lock()</span><br><span class="line">    A=0</span><br><span class="line">    t1=threading.Thread(target=job1)</span><br><span class="line">    t2=threading.Thread(target=job2)</span><br><span class="line">    t1.start()</span><br><span class="line">    t2.start()</span><br><span class="line">    t1.join()</span><br><span class="line">    t2.join()</span><br></pre></td></tr></table></figure><p>运行结果（在spyder编译器下运行的打印结果）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">job1job2 11</span><br><span class="line">job2 21</span><br><span class="line">job2 31</span><br><span class="line">job2 41</span><br><span class="line">job2 51</span><br><span class="line">job2 61</span><br><span class="line">job2 71</span><br><span class="line">job2 81</span><br><span class="line">job2 91</span><br><span class="line">job2 101</span><br><span class="line"> 1</span><br><span class="line">job1 102</span><br><span class="line">job1 103</span><br><span class="line">job1 104</span><br><span class="line">job1 105</span><br><span class="line">job1 106</span><br><span class="line">job1 107</span><br><span class="line">job1 108</span><br><span class="line">job1 109</span><br><span class="line">job1 110</span><br></pre></td></tr></table></figure><p>可以看出，打印的结果非常混乱</p><h2 id="使用-Lock-的情况"><a href="#使用-Lock-的情况" class="headerlink" title="使用 Lock 的情况"></a>使用 Lock 的情况</h2><p>lock在不同线程使用同一共享内存时，能够确保线程之间互不影响，使用lock的方法是， 在每个线程执行运算修改共享内存之前，执行<code>lock.acquire()</code>将共享内存上锁， 确保当前线程执行时，内存不会被其他线程访问，执行运算完毕后，使用<code>lock.release()</code>将锁打开， 保证其他的线程可以使用该共享内存。</p><p>函数一和函数二加锁</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">def job1():</span><br><span class="line">    global A,lock</span><br><span class="line">    lock.acquire()</span><br><span class="line">    for i in range(10):</span><br><span class="line">        A+=1</span><br><span class="line">        print(&apos;job1&apos;,A)</span><br><span class="line">    lock.release()</span><br><span class="line"></span><br><span class="line">def job2():</span><br><span class="line">    global A,lock</span><br><span class="line">    lock.acquire()</span><br><span class="line">    for i in range(10):</span><br><span class="line">        A+=10</span><br><span class="line">        print(&apos;job2&apos;,A)</span><br><span class="line">    lock.release()</span><br></pre></td></tr></table></figure><p>主函数中定义一个<code>Lock</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">if __name__== &apos;__main__&apos;:</span><br><span class="line">    lock=threading.Lock()</span><br><span class="line">    A=0</span><br><span class="line">    t1=threading.Thread(target=job1)</span><br><span class="line">    t2=threading.Thread(target=job2)</span><br><span class="line">    t1.start()</span><br><span class="line">    t2.start()</span><br><span class="line">    t1.join()</span><br><span class="line">    t2.join()</span><br></pre></td></tr></table></figure><p>完整的代码</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">import threading</span><br><span class="line"></span><br><span class="line">def job1():</span><br><span class="line">    global A,lock</span><br><span class="line">    lock.acquire()</span><br><span class="line">    for i in range(10):</span><br><span class="line">        A+=1</span><br><span class="line">        print(&apos;job1&apos;,A)</span><br><span class="line">    lock.release()</span><br><span class="line"></span><br><span class="line">def job2():</span><br><span class="line">    global A,lock</span><br><span class="line">    lock.acquire()</span><br><span class="line">    for i in range(10):</span><br><span class="line">        A+=10</span><br><span class="line">        print(&apos;job2&apos;,A)</span><br><span class="line">    lock.release()</span><br><span class="line"></span><br><span class="line">if __name__== &apos;__main__&apos;:</span><br><span class="line">    lock=threading.Lock()</span><br><span class="line">    A=0</span><br><span class="line">    t1=threading.Thread(target=job1)</span><br><span class="line">    t2=threading.Thread(target=job2)</span><br><span class="line">    t1.start()</span><br><span class="line">    t2.start()</span><br><span class="line">    t1.join()</span><br><span class="line">    t2.join()</span><br></pre></td></tr></table></figure><p>运行结果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">job1 1</span><br><span class="line">job1 2</span><br><span class="line">job1 3</span><br><span class="line">job1 4</span><br><span class="line">job1 5</span><br><span class="line">job1 6</span><br><span class="line">job1 7</span><br><span class="line">job1 8</span><br><span class="line">job1 9</span><br><span class="line">job1 10</span><br><span class="line">job2 20</span><br><span class="line">job2 30</span><br><span class="line">job2 40</span><br><span class="line">job2 50</span><br><span class="line">job2 60</span><br><span class="line">job2 70</span><br><span class="line">job2 80</span><br><span class="line">job2 90</span><br><span class="line">job2 100</span><br><span class="line">job2 110</span><br></pre></td></tr></table></figure><p>从打印结果来看，使用<code>lock</code>后，一个一个线程执行完。使用<code>lock</code>和不使用<code>lock</code>，最后打印输出的结果是不同的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;不使用lock的情况&quot;&gt;&lt;a href=&quot;#不使用lock的情况&quot; class=&quot;headerlink&quot; title=&quot;不使用lock的情况&quot;&gt;&lt;/a&gt;不使用lock的情况&lt;/h2&gt;&lt;p&gt;函数一：全局变量A的值每次加1，循环10次，并打印&lt;/p&gt;
&lt;figure 
      
    
    </summary>
    
      <category term="python" scheme="http://reworth.site/categories/python/"/>
    
    
      <category term="threading" scheme="http://reworth.site/tags/threading/"/>
    
  </entry>
  
  <entry>
    <title>路由协议</title>
    <link href="http://reworth.site/2018/01/19/%E8%B7%AF%E7%94%B1%E5%8D%8F%E8%AE%AE/"/>
    <id>http://reworth.site/2018/01/19/路由协议/</id>
    <published>2018-01-19T06:29:35.000Z</published>
    <updated>2018-01-19T06:31:16.726Z</updated>
    
    <content type="html"><![CDATA[<h1 id="路由控制的定义"><a href="#路由控制的定义" class="headerlink" title="路由控制的定义"></a>路由控制的定义</h1><h2 id="IP地址与路由控制"><a href="#IP地址与路由控制" class="headerlink" title="IP地址与路由控制"></a>IP地址与路由控制</h2><p>互联网是由路由器连接的网络组合而成的，为了能让数据包正确达到目标主机，路由器必须在途中进行正确的转发。这种向“正确方向”装发数据所进行的处理就叫做路由控制或路由。<br>路由器是根据路由控制表转发数据。</p><h2 id="静态路由与动态路由"><a href="#静态路由与动态路由" class="headerlink" title="静态路由与动态路由"></a>静态路由与动态路由</h2><p>静态路由是指事先设置好路由器和主机中将路由信息固定的一种方法。<br>动态路由是指让路由协议在运行过程中自动地设置路由控制信息的一种方法。</p><h1 id="路由控制范围"><a href="#路由控制范围" class="headerlink" title="路由控制范围"></a>路由控制范围</h1><p>人们根据路由控制的范围常使用IGP（Interior Gateway Protocol）和EGP（Exterior Gateway Protocol）两种类型的路由协议。</p><h1 id="路由算法"><a href="#路由算法" class="headerlink" title="路由算法"></a>路由算法</h1><p>路由控制有各种各样的算法，其中最具代表性的两种，是距离向量（Distance-Vector）算法和链路状态（Link-State）算法。<br>距离向量算法DV是根据距离和方向决定目标网络或目标主机位置的一种方法。<br>链路状态算法是路由器在了解网络整体连接状态的基础上生成路由控制表的一种方法。</p><h1 id="主要路由协议"><a href="#主要路由协议" class="headerlink" title="主要路由协议"></a>主要路由协议</h1><table><thead><tr><th>路由协议名</th><th>下一层协议</th><th>方式</th><th>使用范围</th><th>循环检测</th></tr></thead><tbody><tr><td> RIP</td><td>UDP</td><td>距离向量</td><td>域内</td><td>不可以</td></tr><tr><td> RIP2</td><td>UDP</td><td>距离向量</td><td>域内</td><td>不可以</td></tr><tr><td> OSFP</td><td>IP</td><td>链路状态</td><td>域内</td><td>可以</td></tr><tr><td> EGP</td><td>IP</td><td>距离向量</td><td>对外连接</td><td>不可以</td></tr><tr><td> BGP</td><td>TCP</td><td>距离向量</td><td>对外连接</td><td>不可以</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;路由控制的定义&quot;&gt;&lt;a href=&quot;#路由控制的定义&quot; class=&quot;headerlink&quot; title=&quot;路由控制的定义&quot;&gt;&lt;/a&gt;路由控制的定义&lt;/h1&gt;&lt;h2 id=&quot;IP地址与路由控制&quot;&gt;&lt;a href=&quot;#IP地址与路由控制&quot; class=&quot;header
      
    
    </summary>
    
      <category term="Network" scheme="http://reworth.site/categories/Network/"/>
    
    
      <category term="network" scheme="http://reworth.site/tags/network/"/>
    
  </entry>
  
  <entry>
    <title>Redis-Persistence</title>
    <link href="http://reworth.site/2018/01/17/Redis-Persistence/"/>
    <id>http://reworth.site/2018/01/17/Redis-Persistence/</id>
    <published>2018-01-17T07:23:11.000Z</published>
    <updated>2018-01-17T07:27:58.416Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Redis-Persistence"><a href="#Redis-Persistence" class="headerlink" title="Redis Persistence"></a>Redis Persistence</h1><p>Redis provides a different range of persistence options:</p><ul><li>The RDB persistence performs point-in-time snapshots of your dataset at specified intervals.</li><li>the AOF persistence logs every write operation received by the server, that will be played again at server startup, reconstructing the original dataset. Commands are logged using the same format as the Redis protocol itself, in an append-only fashion. Redis is able to rewrite the log on background when it gets too big.</li><li>If you wish, you can disable persistence at all, if you want your data to just exist as long as the server is running.</li><li>It is possible to combine both AOF and RDB in the same instance. Notice that, in this case, when Redis restarts the AOF file will be used to reconstruct the original dataset since it is guaranteed to be the most complete.</li></ul><p>The most important thing to understand is the different trade-offs between the RDB and AOF persistence. Let’s start with RDB:</p><h2 id="RDB-advantages"><a href="#RDB-advantages" class="headerlink" title="RDB advantages"></a>RDB advantages</h2><ul><li>RDB is a very compact single-file point-in-time representation of your Redis data. RDB files are perfect for backups. For instance you may want to archive your RDB files every hour for the latest 24 hours, and to save an RDB snapshot every day for 30 days. This allows you to easily restore different versions of the data set in case of disasters.</li><li>RDB is very good for disaster recovery, being a single compact file can be transferred to far data centers, or on Amazon S3 (possibly encrypted).</li><li>RDB maximizes Redis performances since the only work the Redis parent process needs to do in order to persist is forking a child that will do all the rest. The parent instance will never perform disk I/O or alike.</li><li>RDB allows faster restarts with big datasets compared to AOF.</li></ul><h2 id="RDB-disadvantages"><a href="#RDB-disadvantages" class="headerlink" title="RDB disadvantages"></a>RDB disadvantages</h2><ul><li>RDB is NOT good if you need to minimize the chance of data loss in case Redis stops working (for example after a power outage). You can configure different <em>save points</em> where an RDB is produced (for instance after at least five minutes and 100 writes against the data set, but you can have multiple save points). However you’ll usually create an RDB snapshot every five minutes or more, so in case of Redis stopping working without a correct shutdown for any reason you should be prepared to lose the latest minutes of data.</li><li>RDB needs to fork() often in order to persist on disk using a child process. Fork() can be time consuming if the dataset is big, and may result in Redis to stop serving clients for some millisecond or even for one second if the dataset is very big and the CPU performance not great. AOF also needs to fork() but you can tune how often you want to rewrite your logs without any trade-off on durability.</li></ul><h2 id="AOF-advantages"><a href="#AOF-advantages" class="headerlink" title="AOF advantages"></a>AOF advantages</h2><ul><li>Using AOF Redis is much more durable: you can have different fsync policies: no fsync at all, fsync every second, fsync at every query. With the default policy of fsync every second write performances are still great (fsync is performed using a background thread and the main thread will try hard to perform writes when no fsync is in progress.) but you can only lose one second worth of writes.</li><li>The AOF log is an append only log, so there are no seeks, nor corruption problems if there is a power outage. Even if the log ends with an half-written command for some reason (disk full or other reasons) the redis-check-aof tool is able to fix it easily.</li><li>Redis is able to automatically rewrite the AOF in background when it gets too big. The rewrite is completely safe as while Redis continues appending to the old file, a completely new one is produced with the minimal set of operations needed to create the current data set, and once this second file is ready Redis switches the two and starts appending to the new one.</li><li>AOF contains a log of all the operations one after the other in an easy to understand and parse format. You can even easily export an AOF file. For instance even if you flushed everything for an error using a FLUSHALL command, if no rewrite of the log was performed in the meantime you can still save your data set just stopping the server, removing the latest command, and restarting Redis again.</li></ul><h2 id="AOF-disadvantages"><a href="#AOF-disadvantages" class="headerlink" title="AOF disadvantages"></a>AOF disadvantages</h2><ul><li>AOF files are usually bigger than the equivalent RDB files for the same dataset.</li><li>AOF can be slower than RDB depending on the exact fsync policy. In general with fsync set to <em>every second</em> performances are still very high, and with fsync disabled it should be exactly as fast as RDB even under high load. Still RDB is able to provide more guarantees about the maximum latency even in the case of an huge write load.</li><li>In the past we experienced rare bugs in specific commands (for instance there was one involving blocking commands like BRPOPLPUSH) causing the AOF produced to not reproduce exactly the same dataset on reloading. This bugs are rare and we have tests in the test suite creating random complex datasets automatically and reloading them to check everything is ok, but this kind of bugs are almost impossible with RDB persistence. To make this point more clear: the Redis AOF works incrementally updating an existing state, like MySQL or MongoDB does, while the RDB snapshotting creates everything from scratch again and again, that is conceptually more robust. However - 1) It should be noted that every time the AOF is rewritten by Redis it is recreated from scratch starting from the actual data contained in the data set, making resistance to bugs stronger compared to an always appending AOF file (or one rewritten reading the old AOF instead of reading the data in memory). 2) We never had a single report from users about an AOF corruption that was detected in the real world.</li></ul><h2 id="Ok-so-what-should-I-use"><a href="#Ok-so-what-should-I-use" class="headerlink" title="Ok, so what should I use?"></a>Ok, so what should I use?</h2><p>The general indication is that you should use both persistence methods if you want a degree of data safety comparable to what PostgreSQL can provide you.</p><p>If you care a lot about your data, but still can live with a few minutes of data loss in case of disasters, you can simply use RDB alone.</p><p>There are many users using AOF alone, but we discourage it since to have an RDB snapshot from time to time is a great idea for doing database backups, for faster restarts, and in the event of bugs in the AOF engine.</p><p>Note: for all these reasons we’ll likely end up unifying AOF and RDB into a single persistence model in the future (long term plan).</p><p>The following sections will illustrate a few more details about the two persistence models.</p><h2 id="Snapshotting"><a href="#Snapshotting" class="headerlink" title="Snapshotting"></a>Snapshotting</h2><p>By default Redis saves snapshots of the dataset on disk, in a binary file called <code>dump.rdb</code>. You can configure Redis to have it save the dataset every N seconds if there are at least M changes in the dataset, or you can manually call the <a href="https://redis.io/commands/save" target="_blank" rel="noopener">SAVE</a> or <a href="https://redis.io/commands/bgsave" target="_blank" rel="noopener">BGSAVE</a>commands.</p><p>For example, this configuration will make Redis automatically dump the dataset to disk every 60 seconds if at least 1000 keys changed:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">save 60 1000</span><br></pre></td></tr></table></figure><p>This strategy is known as <em>snapshotting</em>.</p><h3 id="How-it-works"><a href="#How-it-works" class="headerlink" title="How it works"></a>How it works</h3><p>Whenever Redis needs to dump the dataset to disk, this is what happens:</p><ul><li><p>Redis <a href="http://linux.die.net/man/2/fork" target="_blank" rel="noopener">forks</a>. We now have a child and a parent process.</p></li><li><p>The child starts to write the dataset to a temporary RDB file.</p></li><li><p>When the child is done writing the new RDB file, it replaces the old one.</p></li></ul><p>This method allows Redis to benefit from copy-on-write semantics.</p><h2 id="Append-only-file"><a href="#Append-only-file" class="headerlink" title="Append-only file"></a>Append-only file</h2><p>Snapshotting is not very durable. If your computer running Redis stops, your power line fails, or you accidentally <code>kill -9</code> your instance, the latest data written on Redis will get lost. While this may not be a big deal for some applications, there are use cases for full durability, and in these cases Redis was not a viable option.</p><p>The <em>append-only file</em> is an alternative, fully-durable strategy for Redis. It became available in version 1.1.</p><p>You can turn on the AOF in your configuration file:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">appendonly yes</span><br></pre></td></tr></table></figure><p>From now on, every time Redis receives a command that changes the dataset (e.g. <a href="https://redis.io/commands/set" target="_blank" rel="noopener">SET</a>) it will append it to the AOF. When you restart Redis it will re-play the AOF to rebuild the state.</p><h3 id="Log-rewriting"><a href="#Log-rewriting" class="headerlink" title="Log rewriting"></a>Log rewriting</h3><p>As you can guess, the AOF gets bigger and bigger as write operations are performed. For example, if you are incrementing a counter 100 times, you’ll end up with a single key in your dataset containing the final value, but 100 entries in your AOF. 99 of those entries are not needed to rebuild the current state.</p><p>So Redis supports an interesting feature: it is able to rebuild the AOF in the background without interrupting service to clients. Whenever you issue a <a href="https://redis.io/commands/bgrewriteaof" target="_blank" rel="noopener">BGREWRITEAOF</a> Redis will write the shortest sequence of commands needed to rebuild the current dataset in memory. If you’re using the AOF with Redis 2.2 you’ll need to run <a href="https://redis.io/commands/bgrewriteaof" target="_blank" rel="noopener">BGREWRITEAOF</a> from time to time. Redis 2.4 is able to trigger log rewriting automatically (see the 2.4 example configuration file for more information).</p><h3 id="How-durable-is-the-append-only-file"><a href="#How-durable-is-the-append-only-file" class="headerlink" title="How durable is the append only file?"></a>How durable is the append only file?</h3><p>You can configure how many times Redis will <a href="http://linux.die.net/man/2/fsync" target="_blank" rel="noopener"><code>fsync</code></a> data on disk. There are three options:</p><ul><li><p><code>fsync</code> every time a new command is appended to the AOF. Very very slow, very safe.</p></li><li><p><code>fsync</code> every second. Fast enough (in 2.4 likely to be as fast as snapshotting), and you can lose 1 second of data if there is a disaster.</p></li><li><p>Never <code>fsync</code>, just put your data in the hands of the Operating System. The faster and less safe method.</p></li></ul><p>The suggested (and default) policy is to <code>fsync</code> every second. It is both very fast and pretty safe. The <code>always</code> policy is very slow in practice (although it was improved in Redis 2.0) – there is no way to make <code>fsync</code> faster than it is.</p><h3 id="What-should-I-do-if-my-AOF-gets-corrupted"><a href="#What-should-I-do-if-my-AOF-gets-corrupted" class="headerlink" title="What should I do if my AOF gets corrupted?"></a>What should I do if my AOF gets corrupted?</h3><p>It is possible that the server crashes while writing the AOF file (this still should never lead to inconsistencies), corrupting the file in a way that is no longer loadable by Redis. When this happens you can fix this problem using the following procedure:</p><ul><li><p>Make a backup copy of your AOF file.</p></li><li><p>Fix the original file using the <code>redis-check-aof</code> tool that ships with Redis:</p><p>$ redis-check-aof –fix<filename></filename></p></li><li><p>Optionally use <code>diff -u</code> to check what is the difference between two files.</p></li><li><p>Restart the server with the fixed file.</p></li></ul><h3 id="How-it-works-1"><a href="#How-it-works-1" class="headerlink" title="How it works"></a>How it works</h3><p>Log rewriting uses the same copy-on-write trick already in use for snapshotting. This is how it works:</p><ul><li><p>Redis <a href="http://linux.die.net/man/2/fork" target="_blank" rel="noopener">forks</a>, so now we have a child and a parent process.</p></li><li><p>The child starts writing the new AOF in a temporary file.</p></li><li><p>The parent accumulates all the new changes in an in-memory buffer (but at the same time it writes the new changes in the old append-only file, so if the rewriting fails, we are safe).</p></li><li><p>When the child is done rewriting the file, the parent gets a signal, and appends the in-memory buffer at the end of the file generated by the child.</p></li><li><p>Profit! Now Redis atomically renames the old file into the new one, and starts appending new data into the new file.</p></li></ul><h3 id="How-I-can-switch-to-AOF-if-I’m-currently-using-dump-rdb-snapshots"><a href="#How-I-can-switch-to-AOF-if-I’m-currently-using-dump-rdb-snapshots" class="headerlink" title="How I can switch to AOF, if I’m currently using dump.rdb snapshots?"></a>How I can switch to AOF, if I’m currently using dump.rdb snapshots?</h3><p>There is a different procedure to do this in Redis 2.0 and Redis 2.2, as you can guess it’s simpler in Redis 2.2 and does not require a restart at all.</p><p><strong>Redis &gt;= 2.2</strong></p><ul><li>Make a backup of your latest dump.rdb file.</li><li>Transfer this backup into a safe place.</li><li>Issue the following two commands:</li><li>redis-cli config set appendonly yes</li><li>redis-cli config set save “”</li><li>Make sure that your database contains the same number of keys it contained.</li><li>Make sure that writes are appended to the append only file correctly.</li></ul><p>The first CONFIG command enables the Append Only File. In order to do so <strong>Redis will block</strong> to generate the initial dump, then will open the file for writing, and will start appending all the next write queries.</p><p>The second CONFIG command is used to turn off snapshotting persistence. This is optional, if you wish you can take both the persistence methods enabled.</p><p><strong>IMPORTANT:</strong> remember to edit your redis.conf to turn on the AOF, otherwise when you restart the server the configuration changes will be lost and the server will start again with the old configuration.</p><p><strong>Redis 2.0</strong></p><ul><li>Make a backup of your latest dump.rdb file.</li><li>Transfer this backup into a safe place.</li><li>Stop all the writes against the database!</li><li>Issue a redis-cli bgrewriteaof. This will create the append only file.</li><li>Stop the server when Redis finished generating the AOF dump.</li><li>Edit redis.conf end enable append only file persistence.</li><li>Restart the server.</li><li>Make sure that your database contains the same number of keys it contained.</li><li>Make sure that writes are appended to the append only file correctly.</li></ul><h2 id="Interactions-between-AOF-and-RDB-persistence"><a href="#Interactions-between-AOF-and-RDB-persistence" class="headerlink" title="Interactions between AOF and RDB persistence"></a>Interactions between AOF and RDB persistence</h2><p>Redis &gt;= 2.4 makes sure to avoid triggering an AOF rewrite when an RDB snapshotting operation is already in progress, or allowing a BGSAVE while the AOF rewrite is in progress. This prevents two Redis background processes from doing heavy disk I/O at the same time.</p><p>When snapshotting is in progress and the user explicitly requests a log rewrite operation using BGREWRITEAOF the server will reply with an OK status code telling the user the operation is scheduled, and the rewrite will start once the snapshotting is completed.</p><p>In the case both AOF and RDB persistence are enabled and Redis restarts the AOF file will be used to reconstruct the original dataset since it is guaranteed to be the most complete.</p><h2 id="Backing-up-Redis-data"><a href="#Backing-up-Redis-data" class="headerlink" title="Backing up Redis data"></a>Backing up Redis data</h2><p>Before starting this section, make sure to read the following sentence: <strong>Make Sure to Backup Your Database</strong>. Disks break, instances in the cloud disappear, and so forth: no backups means huge risk of data disappearing into /dev/null.</p><p>Redis is very data backup friendly since you can copy RDB files while the database is running: the RDB is never modified once produced, and while it gets produced it uses a temporary name and is renamed into its final destination atomically using rename(2) only when the new snapshot is complete.</p><p>This means that copying the RDB file is completely safe while the server is running. This is what we suggest:</p><ul><li>Create a cron job in your server creating hourly snapshots of the RDB file in one directory, and daily snapshots in a different directory.</li><li>Every time the cron script runs, make sure to call the <code>find</code> command to make sure too old snapshots are deleted: for instance you can take hourly snapshots for the latest 48 hours, and daily snapshots for one or two months. Make sure to name the snapshots with data and time information.</li><li>At least one time every day make sure to transfer an RDB snapshot <em>outside your data center</em> or at least <em>outside the physical machine</em> running your Redis instance.</li></ul><h2 id="Disaster-recovery"><a href="#Disaster-recovery" class="headerlink" title="Disaster recovery"></a>Disaster recovery</h2><p>Disaster recovery in the context of Redis is basically the same story as backups, plus the ability to transfer those backups in many different external data centers. This way data is secured even in the case of some catastrophic event affecting the main data center where Redis is running and producing its snapshots.</p><p>Since many Redis users are in the startup scene and thus don’t have plenty of money to spend we’ll review the most interesting disaster recovery techniques that don’t have too high costs.</p><ul><li>Amazon S3 and other similar services are a good way for mounting your disaster recovery system. Simply transfer your daily or hourly RDB snapshot to S3 in an encrypted form. You can encrypt your data using <code>gpg -c</code> (in symmetric encryption mode). Make sure to store your password in many different safe places (for instance give a copy to the most important people of your organization). It is recommended to use multiple storage services for improved data safety.</li><li>Transfer your snapshots using SCP (part of SSH) to far servers. This is a fairly simple and safe route: get a small VPS in a place that is very far from you, install ssh there, and generate an ssh client key without passphrase, then add it in the authorized_keys file of your small VPS. You are ready to transfer backups in an automated fashion. Get at least two VPS in two different providers for best results.</li></ul><p>It is important to understand that this system can easily fail if not coded in the right way. At least make absolutely sure that after the transfer is completed you are able to verify the file size (that should match the one of the file you copied) and possibly the SHA1 digest if you are using a VPS.</p><p>You also need some kind of independent alert system if the transfer of fresh backups is not working for some reason.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Redis-Persistence&quot;&gt;&lt;a href=&quot;#Redis-Persistence&quot; class=&quot;headerlink&quot; title=&quot;Redis Persistence&quot;&gt;&lt;/a&gt;Redis Persistence&lt;/h1&gt;&lt;p&gt;Redis prov
      
    
    </summary>
    
    
      <category term="redis" scheme="http://reworth.site/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis-introduction</title>
    <link href="http://reworth.site/2018/01/16/redis-introduction/"/>
    <id>http://reworth.site/2018/01/16/redis-introduction/</id>
    <published>2018-01-16T10:14:03.000Z</published>
    <updated>2018-01-16T10:32:23.007Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是Redis"><a href="#什么是Redis" class="headerlink" title="什么是Redis"></a>什么是Redis</h2><p>redis是远程的;<br>redis是基于内存的;<br>redis是非关系型数据库.<br>优点：<br>1.支持丰富的数据类型：String，List，Set，Sorted Set，Hash等<br>2.支持两种数据持久化方式：Snapshotting（内存快照）和Append-Only file（日志追加）<br>3.支持主从复制</p><h2 id="Redis的应用场景"><a href="#Redis的应用场景" class="headerlink" title="Redis的应用场景"></a>Redis的应用场景</h2><ul><li>缓存</li><li>队列–使用list结构</li><li>数据存储</li></ul><h2 id="Redis数据类型"><a href="#Redis数据类型" class="headerlink" title="Redis数据类型"></a>Redis数据类型</h2><style>table th:first-of-type {    width: 100px;}</style><table><thead><tr><th>数据类型</th><th>存储的值</th><th>读写能力</th></tr></thead><tbody><tr><td>String</td><td>可以是字符串，整数或者浮点，统称为元素</td><td>对字符串操作，对整数类型加减</td></tr><tr><td>List</td><td>一个序列集合且每个节点都包好了一个元素</td><td>序列两端推入或弹出元素</td></tr><tr><td>Set</td><td>各个不同的元素</td><td>从集合中插入或删除元素</td></tr><tr><td>Hash</td><td>有key-value的散列组，其中key是字符串，value是元素</td><td>按照key进行增加删除</td></tr><tr><td>Sort Set</td><td>带分数的score-value有序集合，其中score是浮点，value是元素</td><td>集合插入，按照分数范围查找</td></tr></tbody></table><ul><li><p>String</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># key       value(string/int/float)</span><br><span class="line">127.0.0.1:6379&gt; set string1 demo</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; get string1</span><br><span class="line">&quot;demo&quot;</span><br><span class="line">127.0.0.1:6379&gt; set string2 4</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; get string2</span><br><span class="line">&quot;4&quot; </span><br><span class="line">127.0.0.1:6379&gt; incr string2 #对整型进行自增操作</span><br><span class="line">(integer) 5</span><br><span class="line">127.0.0.1:6379&gt; get string2</span><br><span class="line">&quot;5&quot;</span><br><span class="line">127.0.0.1:6379&gt; decrby string2 2 #对整型进行减法操作，将string2减去2</span><br><span class="line">(integer) 3</span><br><span class="line">127.0.0.1:6379&gt; get string2</span><br><span class="line">&quot;3&quot;</span><br></pre></td></tr></table></figure></li><li><p>List类型</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; lpush list1 12 #lpush表示从左边push一个元素到list1中，l表示left</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; lpush list1 13</span><br><span class="line">(interger) 2</span><br><span class="line">127.0.0.1:6379&gt; rpop list1  #rpop表示从右侧pop出一个元素，按照先入先出的原则</span><br><span class="line">“12”</span><br><span class="line">127.0.0.1:6379&gt; lpush list2 12</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; lpush list2 13</span><br><span class="line">(integer) 2</span><br><span class="line">127.0.0.1:6379&gt; lpush list2 13 #list类型不要求集合中的元素唯一，所以可以插入相同的元素，而set类型要求集合中元素必须唯一</span><br><span class="line">(integer) 3</span><br><span class="line">127.0.0.1:6379&gt; llen list2 #llen命令列出list2中元素的个数</span><br><span class="line">(integer) 3</span><br></pre></td></tr></table></figure></li><li><p>Set类型</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; sadd set1 12</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; scard set1 #用scard查看set1中的元素个数</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; sadd set1 13</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; sadd set1 13</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; scard set1</span><br><span class="line">(integer) 2</span><br><span class="line">127.0.0.1:6379&gt; sismember set1 13 #sismember 命令判断13是否在set1中</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; srem set1 13  #srem命令将13从set1中删除</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; sismember set1 13 </span><br><span class="line">(integer) 0</span><br></pre></td></tr></table></figure></li><li><p>Hash类型</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; hset hash1 key1 12 #hset命令设置hash1的键为key1,值为12</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt;  hget hash1 key1 #hget命令获取hash1键名为key1的值</span><br><span class="line">&quot;12&quot;</span><br><span class="line">127.0.0.1:6379&gt; hset hash1 key2 13</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; hset hash1 key3 13</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; hlen hash1 #hlen命令获取hash1的长度</span><br><span class="line">(integer) 3</span><br><span class="line">127.0.0.1:6379&gt; hset hash1 key3 14 #直接修改hash1中key3的值</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt;  hget hash1 key3</span><br><span class="line">&quot;14&quot;</span><br><span class="line">127.0.0.1:6379&gt;  hmget hash1 key1 key2  #hmget 命令一次获取多个key的值</span><br><span class="line">1) &quot;12&quot;</span><br><span class="line">2) &quot;13&quot;</span><br></pre></td></tr></table></figure></li><li><p>Sort Set类型</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; zadd zset1 10.1 val1  #zadd命令往zset1中添加一个元素，score为10.1，value为val1</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; zadd zset1 11.2 val2</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; zadd zset1 9.1 val3</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; zcard zset1  #zcard 命令查看zset1中的元素值</span><br><span class="line">(integer) 3</span><br><span class="line">127.0.0.1:6379&gt; zrange zset1 0 2 withscores #zrange 命令打印出排名</span><br><span class="line">1) &quot;val3&quot;</span><br><span class="line">2) &quot;9.1&quot;</span><br><span class="line">3) &quot;val1&quot;</span><br><span class="line">4) &quot;10.1&quot;</span><br><span class="line">5) &quot;val2&quot;</span><br><span class="line">6) &quot;11.19999999&quot;</span><br><span class="line">127.0.0.1:6379&gt; zrange zset1 val2 #打印出val2的排名</span><br><span class="line">(integer) 2</span><br><span class="line">127.0.0.1:6379&gt; zadd zset1 12.2 val3</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; zrange zset1 0 2 withscores</span><br><span class="line">1) &quot;val1&quot;</span><br><span class="line">2) &quot;10.1&quot;</span><br><span class="line">3) &quot;val2&quot;</span><br><span class="line">4) &quot;11.19999999&quot;</span><br><span class="line">5) &quot;val3&quot;</span><br><span class="line">6) &quot;12.19999999&quot;</span><br><span class="line">127.0.0.1:6379&gt; zadd zset1 12.2 val2</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; zrange zset1 0 2 withscores</span><br><span class="line">1) &quot;val1&quot;</span><br><span class="line">2) &quot;10.1&quot;</span><br><span class="line">3) &quot;val2&quot;</span><br><span class="line">4) &quot;12.19999999&quot;</span><br><span class="line">5) &quot;val3&quot;</span><br><span class="line">6) &quot;12.19999999&quot;</span><br></pre></td></tr></table></figure></li></ul><h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><h4 id="键值相关命令"><a href="#键值相关命令" class="headerlink" title="键值相关命令"></a>键值相关命令</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line">// 1. keys *，代表取出所有的 key</span><br><span class="line"> redis 127.0.0.1:6379&gt; keys *</span><br><span class="line">1) &quot;myzset2&quot;</span><br><span class="line">2) &quot;myzset3&quot;</span><br><span class="line">3) &quot;mylist&quot;</span><br><span class="line">4) &quot;myset2&quot;</span><br><span class="line">5) &quot;myset3&quot;</span><br><span class="line">6) &quot;myset4&quot;</span><br><span class="line">7) &quot;k_zs_1&quot;</span><br><span class="line">8) &quot;myset5&quot;</span><br><span class="line">9) &quot;myset6&quot;</span><br><span class="line">10) &quot;myset7&quot;</span><br><span class="line">11) &quot;myhash&quot;</span><br><span class="line">12) &quot;myzset&quot;</span><br><span class="line">13) &quot;age&quot;</span><br><span class="line">14) &quot;myset&quot;</span><br><span class="line">15) &quot;mylist5&quot;</span><br><span class="line">16) &quot;mylist6&quot;</span><br><span class="line">redis 127.0.0.1:6379&gt; keys mylist*</span><br><span class="line">1) &quot;mylist&quot;</span><br><span class="line">2) &quot;mylist5&quot;</span><br><span class="line">3) &quot;mylist6&quot;</span><br><span class="line">4) &quot;mylist7&quot;</span><br><span class="line">5) &quot;mylist8&quot;</span><br><span class="line">redis 127.0.0.1:6379&gt;</span><br><span class="line">// 2.exists 确认一个 key 是否存在</span><br><span class="line">redis 127.0.0.1:6379&gt; exists HongWan</span><br><span class="line">(integer) 0</span><br><span class="line">redis 127.0.0.1:6379&gt; exists age</span><br><span class="line">(integer) 1</span><br><span class="line">redis 127.0.0.1:6379&gt;</span><br><span class="line">// 3. del 删除一个 key</span><br><span class="line">redis 127.0.0.1:6379&gt; del age</span><br><span class="line">(integer) 1</span><br><span class="line">redis 127.0.0.1:6379&gt; exists age</span><br><span class="line">(integer) 0</span><br><span class="line">redis 127.0.0.1:6379&gt;</span><br><span class="line">// 4. expire 设置一个 key 的过期时间(单位:秒)</span><br><span class="line">redis 127.0.0.1:6379&gt; expire addr 10</span><br><span class="line">(integer) 1</span><br><span class="line">redis 127.0.0.1:6379&gt; ttl addr</span><br><span class="line">(integer) 8</span><br><span class="line">redis 127.0.0.1:6379&gt; ttl addr</span><br><span class="line">(integer) 1</span><br><span class="line">redis 127.0.0.1:6379&gt; ttl addr</span><br><span class="line">(integer) -1</span><br><span class="line">// 们设置 addr 这个 key 的过期时间是 10 秒，然后我们不断的用 ttl 来获取这个 key 的有效时长，直至为-1 说明此值已过期</span><br><span class="line">// 5. move将当前数据库中的 key 转移到其它数据库中</span><br><span class="line">redis 127.0.0.1:6379&gt; select 0</span><br><span class="line">www.ChinaDBA.net 中国 DBA 超级论坛</span><br><span class="line">49</span><br><span class="line">OK</span><br><span class="line">redis 127.0.0.1:6379&gt; set age 30</span><br><span class="line">OK</span><br><span class="line">redis 127.0.0.1:6379&gt; get age</span><br><span class="line">&quot;30&quot;</span><br><span class="line">redis 127.0.0.1:6379&gt; move age 1</span><br><span class="line">(integer) 1</span><br><span class="line">redis 127.0.0.1:6379&gt; get age</span><br><span class="line">(nil)</span><br><span class="line">redis 127.0.0.1:6379&gt; select 1</span><br><span class="line">OK</span><br><span class="line">redis 127.0.0.1:6379[1]&gt; get age</span><br><span class="line">&quot;30&quot;</span><br><span class="line">redis 127.0.0.1:6379[1]&gt;</span><br><span class="line">// 先显式的选择了数据库 0，然后在这个库中设置一个 key，接下来我们将这个key 从数据库 0 移到数据库 1，之后我们确认在数据库 0 中无此 key 了, 但在数据库 1 中存在这个key，说明我们转移成功了</span><br><span class="line">// 6. persist 移除给定 key 的过期时间</span><br><span class="line">redis 127.0.0.1:6379[1]&gt; expire age 300</span><br><span class="line">(integer) 1</span><br><span class="line">redis 127.0.0.1:6379[1]&gt; ttl age</span><br><span class="line">(integer) 294</span><br><span class="line">redis 127.0.0.1:6379[1]&gt; persist age</span><br><span class="line">(integer) 1</span><br><span class="line">redis 127.0.0.1:6379[1]&gt; ttl age</span><br><span class="line">(integer) -1</span><br><span class="line">redis 127.0.0.1:6379[1]&gt;</span><br><span class="line">// 手动的将未到过期时间的 key，成功设置为过期</span><br><span class="line">// 7. randomkey 随机返回 key 空间的一个 key</span><br><span class="line">redis 127.0.0.1:6379&gt; randomkey</span><br><span class="line">&quot;mylist7&quot;</span><br><span class="line">redis 127.0.0.1:6379&gt; randomkey</span><br><span class="line">&quot;mylist5&quot;</span><br><span class="line">redis 127.0.0.1:6379&gt;</span><br><span class="line">// 8. rename 重命名 key</span><br><span class="line">redis 127.0.0.1:6379[1]&gt; keys *</span><br><span class="line">1) &quot;age&quot;</span><br><span class="line">redis 127.0.0.1:6379[1]&gt; rename age age_new</span><br><span class="line">OK</span><br><span class="line">redis 127.0.0.1:6379[1]&gt; keys *</span><br><span class="line">1) &quot;age_new&quot;</span><br><span class="line">// 9.  type 返回值的类型</span><br><span class="line">redis 127.0.0.1:6379&gt; type addr</span><br><span class="line">string</span><br><span class="line">redis 127.0.0.1:6379&gt; type myzset2</span><br><span class="line">zset</span><br><span class="line">redis 127.0.0.1:6379&gt; type mylist</span><br><span class="line">list</span><br></pre></td></tr></table></figure><h4 id="服务器相关命令"><a href="#服务器相关命令" class="headerlink" title="服务器相关命令"></a>服务器相关命令</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">// 1. ping 测试连接是否存活</span><br><span class="line">redis 127.0.0.1:6379&gt; ping</span><br><span class="line">PONG</span><br><span class="line">// 2. echo 在命令行打印一些内容</span><br><span class="line">redis 127.0.0.1:6379&gt; echo Helloworld</span><br><span class="line">&quot;Helloworld&quot;</span><br><span class="line">// 3. select 选择数据库。Redis 数据库编号从 0~15，我们可以选择任意一个数据库来进行数据的存取。</span><br><span class="line">redis 127.0.0.1:6379&gt; select 1</span><br><span class="line">OK</span><br><span class="line">redis 127.0.0.1:6379[1]&gt; select 16</span><br><span class="line">(error) ERR invalid DB index</span><br><span class="line">redis 127.0.0.1:6379[16]&gt;</span><br><span class="line">// 4. quit 退出连接</span><br><span class="line">redis 127.0.0.1:6379&gt; quit</span><br><span class="line">[root@localhost redis-2.2.12]#</span><br><span class="line">// 5.  dbsize 返回当前数据库中 key 的数目</span><br><span class="line">redis 127.0.0.1:6379&gt; dbsize</span><br><span class="line">(integer) 18</span><br><span class="line">redis 127.0.0.1:6379&gt;</span><br><span class="line">// 6.  info 获取服务器的信息和统计</span><br><span class="line">redis 127.0.0.1:6379&gt; info</span><br><span class="line"># Server</span><br><span class="line">redis_version:3.2.100</span><br><span class="line">redis_git_sha1:00000000</span><br><span class="line">redis_git_dirty:0</span><br><span class="line">redis_build_id:dd26f1f93c5130ee</span><br><span class="line">redis_mode:standalone</span><br><span class="line">os:Windows</span><br><span class="line">arch_bits:64</span><br><span class="line">multiplexing_api:WinSock_IOCP</span><br><span class="line">process_id:2528</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">redis 127.0.0.1:6379&gt;</span><br><span class="line">// 7. config get  获取服务器配置信息, config get * 表示获取全部</span><br><span class="line">redis 127.0.0.1:6379&gt; config get dir</span><br><span class="line">1) &quot;dir&quot;</span><br><span class="line">2) &quot;/root/4setup/redis-3.2.100&quot;</span><br><span class="line">redis 127.0.0.1:6379&gt;</span><br><span class="line">// 8. flushdb 删除当前选择数据库中的所有 key</span><br><span class="line">redis 127.0.0.1:6379&gt; dbsize</span><br><span class="line">(integer) 18</span><br><span class="line">redis 127.0.0.1:6379&gt; flushdb</span><br><span class="line">OK</span><br><span class="line">redis 127.0.0.1:6379&gt; dbsize</span><br><span class="line">(integer) 0</span><br><span class="line">// 9. flushall 删除所有数据库中的所有 key</span><br><span class="line">redis 127.0.0.1:6379[1]&gt; dbsize</span><br><span class="line">(integer) 1</span><br><span class="line">redis 127.0.0.1:6379[1]&gt; select 0</span><br><span class="line">OK</span><br><span class="line">redis 127.0.0.1:6379&gt; flushall</span><br><span class="line">OK</span><br><span class="line">redis 127.0.0.1:6379&gt; select 1</span><br><span class="line">OK</span><br><span class="line">redis 127.0.0.1:6379[1]&gt; dbsize</span><br><span class="line">(integer) 0</span><br><span class="line">redis 127.0.0.1:6379[1]&gt;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;什么是Redis&quot;&gt;&lt;a href=&quot;#什么是Redis&quot; class=&quot;headerlink&quot; title=&quot;什么是Redis&quot;&gt;&lt;/a&gt;什么是Redis&lt;/h2&gt;&lt;p&gt;redis是远程的;&lt;br&gt;redis是基于内存的;&lt;br&gt;redis是非关系型数据库.&lt;b
      
    
    </summary>
    
    
      <category term="redis" scheme="http://reworth.site/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>使用Werkzeug实现密码散列</title>
    <link href="http://reworth.site/2018/01/10/%E4%BD%BF%E7%94%A8Werkzeug%E5%AE%9E%E7%8E%B0%E5%AF%86%E7%A0%81%E6%95%A3%E5%88%97/"/>
    <id>http://reworth.site/2018/01/10/使用Werkzeug实现密码散列/</id>
    <published>2018-01-10T07:04:37.000Z</published>
    <updated>2018-01-10T07:08:15.048Z</updated>
    
    <content type="html"><![CDATA[<p>这一功能的实现只需要两个函数，分别用在注册用户和验证用户阶段。</p><ul><li>generate_password_hash(password, method= pbkdf2:sha1 , salt_length=8) :这个函数将原始密码作为输入，以字符串形式输出密码的散列值，输出的值可保存在用户数据库中</li><li>check_password_hash(hash, password) :这个函数的参数是从数据库中取回的密码散列值和用户输入的密码进行比对。返回值为 True 表明密码正确。 </li></ul><p>Sample：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">from werkzeug.security import generate_password_hash, check_password_hash</span><br><span class="line">class User(UserMixin, db.Model):</span><br><span class="line">__tablename__ = &apos;users&apos;</span><br><span class="line">    #...</span><br><span class="line">id = db.Column(db.Integer, primary_key=True)</span><br><span class="line">email = db.Column(db.String(64), unique=True, index=True)</span><br><span class="line">username = db.Column(db.String(64), unique=True, index=True)</span><br><span class="line">password_hash = db.Column(db.String(128))</span><br><span class="line"></span><br><span class="line">@property</span><br><span class="line">def password(self):</span><br><span class="line">raise AttributeError(&apos;password is not a readable attribute&apos;)</span><br><span class="line"></span><br><span class="line">@password.setter</span><br><span class="line">def password(self, password):</span><br><span class="line">self.password_hash = generate_password_hash(password)</span><br><span class="line"></span><br><span class="line">def verify_password(self, password):</span><br><span class="line">return check_password_hash(self.password_hash, password)</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;这一功能的实现只需要两个函数，分别用在注册用户和验证用户阶段。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;generate_password_hash(password, method= pbkdf2:sha1 , salt_length=8) :这个函数将原始密码作为输入，以字符串形式输
      
    
    </summary>
    
      <category term="flask" scheme="http://reworth.site/categories/flask/"/>
    
    
      <category term="flask" scheme="http://reworth.site/tags/flask/"/>
    
      <category term="Werkzeug" scheme="http://reworth.site/tags/Werkzeug/"/>
    
  </entry>
  
  <entry>
    <title>nfs</title>
    <link href="http://reworth.site/2018/01/06/nfs/"/>
    <id>http://reworth.site/2018/01/06/nfs/</id>
    <published>2018-01-06T03:57:17.000Z</published>
    <updated>2018-01-06T06:09:43.255Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是NFS"><a href="#什么是NFS" class="headerlink" title="什么是NFS"></a>什么是NFS</h2><p> NFS就是Network FileSystem的缩写。它最大的功能就是可以透过网络，让不同的机器、不同的操作系统、可以彼此分享个别的档案 。</p><h2 id="什么是RPC"><a href="#什么是RPC" class="headerlink" title="什么是RPC"></a>什么是RPC</h2><p>RPC是Remote Procedure Call的缩写。客户端就是通过远程调用RPC服务才知道该连接服务端的哪个端口号。RPC 最主要的功能就是在指定每个 NFS 功能所对应的 端口号，并且回报给客户端，让客户端可以连结到正确的端口上去。 那 RPC 又是如何知道每个 NFS 的埠口呢？这是因为当服务器在启动NFS 时会随机取用数个端口，并主动的向 RPC 注册，因此 RPC 可以知道每个端口对应的 NFS 功能，然后 RPC 又是固定使用 port 111 来监听客户端的需求并回报客户端正确的端口。<br><strong>NOTE：PRC要在NFS之前启动，否则NFS会无法向RPC注册。</strong><br><img src="http://p1tniwn00.bkt.clouddn.com/nfs_rpc.png" alt="NFS与PRC服务及文件系统相关性"></p><h2 id="NFS启动的RPC-damons"><a href="#NFS启动的RPC-damons" class="headerlink" title="NFS启动的RPC damons"></a>NFS启动的RPC damons</h2><p>我们现在知道 NFS 服务器在启动的时候就得要向 RPC 注册，所以 NFS 服务器也被称为 RPC server 之一。 那么 NFS 服务器主要的任务是进行文件系统的分享，文件系统的分享则与权限有关。 所以 NFS 服务器启动时至少需要两个 daemons ，一个管理客户端是否能够登入的问题， 一个管理客户端能够取得的权限。如果你还想要管理 quota 的话，那么 NFS 还得要再加载其他的 RPC 程序就是了。我们以较单纯的 NFS 服务器来说：</p><ul><li>rpc.nfsd:<br>最主要的 NFS 服务器服务提供商。这个 daemon 主要的功能就是在管理客户端是否能够使用服务器文件系统挂载信息等， 其中还包含这个登入者的 ID 的判别喔！</li><li>rpc.mountd<br>这个 daemon 主要的功能，则是在管理 NFS 的文件系统哩！当客户端顺利的通过 rpc.nfsd 而登入服务器之后，在他可以使用 NFS 服务器提供的档案之前，还会经过档案权限 (就是那个 -rwxrwxrwx 与 owner, group 那几个权限啦) 的认证程序！他会去读 NFS 的配置文件 /etc/exports 来比对客户端的权限，当通过这一关之后客户端就可以取得使用 NFS 档案的权限啦！(注：这个也是我们用来管理 NFS 分享之目录的权限与安全设定的地方哩！)</li><li>rpc.locked(非必要)<br>这个玩意儿可以用在管理档案的锁定 (lock) 用途。为何档案需要『锁定』呢？ 因为既然分享的 NFS 档案可以让客户端使用，那么当多个客户端同时尝试写入某个档案时， 就可能对于该档案造成一些问题啦！这个 rpc.lockd 则可以用来克服这个问题。 但 rpc.lockd 必须要同时在客户端与服务器端都开启才行喔！此外， rpc.lockd 也常与 rpc.statd 同时启用。</li><li>rpc.statd(非必要)<br>可以用来检查档案的一致性，与 rpc.lockd 有关！若发生因为客户端同时使用同一档案造成档案可能有所损毁时， rpc.statd 可以用来检测并尝试回复该档案。与 rpc.lockd 同样的，这个功能必须要在服务器端与客户端都启动才会生效。</li></ul><p><img src="http://p1tniwn00.bkt.clouddn.com/nfs_auth.png" alt="NFS AUTH"></p><h2 id="NFS服务配置"><a href="#NFS服务配置" class="headerlink" title="NFS服务配置"></a>NFS服务配置</h2><h3 id="服务端配置"><a href="#服务端配置" class="headerlink" title="服务端配置"></a>服务端配置</h3><h4 id="安装必要的包"><a href="#安装必要的包" class="headerlink" title="安装必要的包"></a>安装必要的包</h4><p>使用NFS服务需要安装两个包：nfs-utils和rpcbind<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y nfs-utils</span><br></pre></td></tr></table></figure></p><p>使用yum安装nfs-utils时会自动安装rpcbind</p><h4 id="配置-etc-export文件"><a href="#配置-etc-export文件" class="headerlink" title="配置/etc/export文件"></a>配置/etc/export文件</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># vim /etc/exports</span><br><span class="line">/tmp 192.168.100.0/24(ro)  localhost(rw)  *(rw,no_root_squash)</span><br></pre></td></tr></table></figure><p>在配置文件中增加内容，每一行分为三部分：</p><ul><li>本地要共享出去的目录</li><li>允许访问的主机</li><li>权限选项<br>每一行最前面是要分享出来的目录，注意喔！是以目录为单位啊！ 然后这个目录可以依照不同的权限分享给不同的主机，像鸟哥上面的例子说明是： 要将 /tmp 分别分享给三个不同的主机或网域的意思。记得主机后面以小括号 () 设计权限参数， 若权限参数不止一个时，则以逗号 (,) 分开。且主机名与小括号是连在一起的喔！在这个档案内也可以利用 # 来批注呢。<br><strong>权限部分参数说明</strong>：</li><li>rw 表示读/写</li><li>ro 表示只读</li><li>sync 表示数据同步写入内存缓冲区与磁盘中，效率较低，但可以保证数据的一致性（适合于小文件传输）</li><li>async 表示数据先暂时放于内存，而非直接写入硬盘，等到必要时才写入磁盘（适合于大文件传输）</li><li>no_root_squash 表示root用户对这个共享的目录拥有至高的控制权（不安全，不建议使用）</li><li>root_squash 表示root用户对这个共享的目录的权限和普通用户一样。</li><li>all_squash 表示不管使用NFS的用户是谁，其身份都会被限定成一个指定的普通用户。</li><li>no_all_squash 表示所有的普通用户使用nfs都不使用权限压缩（默认设置）</li><li>anonuid/anongid 要和root_squash以及all_squash选项一同使用，用于指定使用NFS的用户被限定后的uid和gid<h4 id="启动NFS服务"><a href="#启动NFS服务" class="headerlink" title="启动NFS服务"></a>启动NFS服务</h4>在启动NFS服务之前，需要先启动rpcbind<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">service rpcbind start</span><br><span class="line">service nfs start</span><br><span class="line">OR</span><br><span class="line">systemctl start rpcbind.service</span><br><span class="line">systemctl stop nfs.service</span><br></pre></td></tr></table></figure></li></ul><h4 id="关闭NFS服务"><a href="#关闭NFS服务" class="headerlink" title="关闭NFS服务"></a>关闭NFS服务</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop rpcbind.service</span><br><span class="line">systemctl stop nfs.service</span><br></pre></td></tr></table></figure><h3 id="客户端挂载NFS"><a href="#客户端挂载NFS" class="headerlink" title="客户端挂载NFS"></a>客户端挂载NFS</h3><h4 id="查看服务器共享的目录"><a href="#查看服务器共享的目录" class="headerlink" title="查看服务器共享的目录"></a>查看服务器共享的目录</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">showmount -e 服务器ip地址</span><br></pre></td></tr></table></figure><p>会得到如下结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Export list for 192.168.0.1:</span><br><span class="line">/data *</span><br></pre></td></tr></table></figure></p><h4 id="在客户端挂载NFS"><a href="#在客户端挂载NFS" class="headerlink" title="在客户端挂载NFS"></a>在客户端挂载NFS</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># mount -t nfs 服务器ip地址:服务器共享目录 挂载点</span><br><span class="line">mount -t nfs 192.168.0.1:/data /mnt</span><br></pre></td></tr></table></figure><p>其中-t nfs指定挂载的类型为nfs</p><h4 id="查看是否挂载成功"><a href="#查看是否挂载成功" class="headerlink" title="查看是否挂载成功"></a>查看是否挂载成功</h4><p>命令df用于查看已挂载磁盘的总容量，使用容量，剩余容量等。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#df -h</span><br></pre></td></tr></table></figure></p><p>-h 表示使用合适的单位显示</p><h4 id="解除挂载"><a href="#解除挂载" class="headerlink" title="解除挂载"></a>解除挂载</h4><p>umount用于解除挂载，格式如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># umount 已挂载的目录</span><br></pre></td></tr></table></figure></p><p>如果遇到：umount.nfs：已挂载目录:device is busy<br>可以添加-l参数，如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># umount -l 已挂载目录</span><br></pre></td></tr></table></figure></p><p>选项-l并不是马上umount，二是在该目录空闲后再umount，即延迟挂载。</p><h4 id="开机自动挂载"><a href="#开机自动挂载" class="headerlink" title="开机自动挂载"></a>开机自动挂载</h4><p>方法A：<br>/etc/fstab里添加如下内容：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 服务器ip地址:共享的目录 客户端挂载点 nfs defaults 1 1</span><br><span class="line">192.168.0.1:/data/    /mnt   nfs     defaults        0 0</span><br></pre></td></tr></table></figure></p><p>第一个1表示备份文件系统，第二个1表示从/分区的顺序开始fsck磁盘检测，0表示不检测。<br>方法B：<br>将手动挂载的命令加入到/etc/rc.local中。<br>命令exportfs<br>命令参数：</p><ul><li>-a表示全部挂载或者卸载</li><li>-r表示重新挂载</li><li>-u表示卸载某一目录</li><li>-v表示显示共享的目录<br>使用命令：<br>修改配置文件/etx/exports后，使用exportfs命令挂载不需要重启NFS服务<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># exportfs -arv</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;什么是NFS&quot;&gt;&lt;a href=&quot;#什么是NFS&quot; class=&quot;headerlink&quot; title=&quot;什么是NFS&quot;&gt;&lt;/a&gt;什么是NFS&lt;/h2&gt;&lt;p&gt; NFS就是Network FileSystem的缩写。它最大的功能就是可以透过网络，让不同的机器、不同的操
      
    
    </summary>
    
      <category term="linux" scheme="http://reworth.site/categories/linux/"/>
    
    
      <category term="nfs" scheme="http://reworth.site/tags/nfs/"/>
    
  </entry>
  
  <entry>
    <title>flask-sqlachemy</title>
    <link href="http://reworth.site/2018/01/05/flask-sqlachemy/"/>
    <id>http://reworth.site/2018/01/05/flask-sqlachemy/</id>
    <published>2018-01-05T02:59:28.000Z</published>
    <updated>2018-01-05T03:07:59.988Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Simple-Example"><a href="#Simple-Example" class="headerlink" title="Simple Example"></a>Simple Example</h2><p>简单的一个例子：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">class User(db.Model):</span><br><span class="line">    id = db.Column(db.Integer, primary_key=True)</span><br><span class="line">    username = db.Column(db.String(80), unique=True, nullable=False)</span><br><span class="line">    email = db.Column(db.String(120), unique=True, nullable=False)</span><br><span class="line"></span><br><span class="line">    def __repr__(self):</span><br><span class="line">        return &apos;&lt;User %r&gt;&apos; % self.username</span><br></pre></td></tr></table></figure></p><p>使用Column定义一个字段。<br><strong>常用字段类型：</strong></p><table><thead><tr><th>类型</th><th>说明</th></tr></thead><tbody><tr><td>Integer</td><td>整数</td></tr><tr><td>String（size）</td><td>有最大长度的字符串</td></tr><tr><td>Text</td><td>长unicode文本</td></tr><tr><td>DateTime</td><td>表示datetime对象的时间和日期</td></tr><tr><td>Float</td><td>存储浮点值</td></tr><tr><td>Boolean</td><td>存储布尔值</td></tr><tr><td>PickleType</td><td>存储一个持久化python对象</td></tr><tr><td>LargeBinary</td><td>存储任意大的二进制数据</td></tr></tbody></table><h2 id="One-to-Many-Relationships"><a href="#One-to-Many-Relationships" class="headerlink" title="One-to-Many Relationships"></a>One-to-Many Relationships</h2><p>最常用的关系就是一对多关系。因为关系在它们建立之前就已经声明，你可以使用 字符串来参考还没有创建的类（比如如果 Person 定义了一个到 Address 的 关系，而这个关系在文件的后面才会声明）。<br>关系用函数relationship()来表示。而外键必须用sqlalchemy.schema.ForeignKey来单独声明:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">class Person(db.Model):</span><br><span class="line">    id = db.Column(db.Integer, primary_key=True)</span><br><span class="line">    name = db.Column(db.String(50))</span><br><span class="line">    addresses = db.relationship(&apos;Address&apos;, backref=&apos;person&apos;,</span><br><span class="line">                                lazy=&apos;dynamic&apos;)</span><br><span class="line"></span><br><span class="line">class Address(db.Model):</span><br><span class="line">    id = db.Column(db.Integer, primary_key=True)</span><br><span class="line">    email = db.Column(db.String(50))</span><br><span class="line">    person_id = db.Column(db.Integer, db.ForeignKey(&apos;person.id&apos;))</span><br></pre></td></tr></table></figure></p><p>db.relationship() 做了什么？这个函数返回一个可以做许多事情的属性。 在本案例中，我们让它指向 Address 类并加载那些中的多个。它如何知道这 会返回至少一个地址？因为 SQLALchemy 从你的声明中猜测了一个有用的默认值。 如果你想要一对一联系，你可以把 uselist=False 传给relationship().</p><blockquote><p>So what do backref and lazy mean? backref is a simple way to also declare a new property on the Address class. You can then also use my_address.person to get to the person at that address. lazy defines when SQLAlchemy will load the data from the database:</p></blockquote><p>那么 backref 和 lazy 意味着什么？ backref 是一个同样在 Address 类 上声明新属性的简单方法。你之后也可以用 my_address.person 来获取这个地址 的人。 lazy 决定了 SQLAlchemy 什么时候从数据库中加载数据:</p><ul><li>‘select’ （默认值）意味着 SQLAlchemy 会在使用一个标准 select 语句 时一气呵成加载那些数据.</li><li>‘joined’ 让 SQLAlchemy 当父级使用 JOIN 语句是，在相同的查询中加 载关系。</li><li>‘subquery’ 类似 ‘joined’ ，但是 SQLAlchemy 会使用子查询。</li><li>‘dynamic’ 在你有很多条目的时侯是特别有用的。 SQLAlchemy 会返回另一个查询对象，你可以在加载这些条目时进一步提取。如果不仅想要关系下的少量条目 时，这通常是你想要的。</li></ul><p>你如何为反向引用（backrefs）定义惰性（lazy）状态？使用backref()函数：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">class User(db.Model):</span><br><span class="line">    id = db.Column(db.Integer, primary_key=True)</span><br><span class="line">    name = db.Column(db.String(50), nullable=False)</span><br><span class="line">    addresses = db.relationship(&apos;Address&apos;, lazy=&apos;select&apos;,</span><br><span class="line">        backref=db.backref(&apos;person&apos;, lazy=&apos;joined&apos;))</span><br></pre></td></tr></table></figure></p><h2 id="Many-to-Many-Relationships"><a href="#Many-to-Many-Relationships" class="headerlink" title="Many-to-Many Relationships"></a>Many-to-Many Relationships</h2><p>如果你想要用多对多关系，你需要定义一个用于关系的辅助表。对于这个辅助表， 强烈建议不使用模型，而是采用一个实际的表:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">tags = db.Table(&apos;tags&apos;,</span><br><span class="line">    db.Column(&apos;tag_id&apos;, db.Integer, db.ForeignKey(&apos;tag.id&apos;)),</span><br><span class="line">    db.Column(&apos;page_id&apos;, db.Integer, db.ForeignKey(&apos;page.id&apos;))</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">class Page(db.Model):</span><br><span class="line">    id = db.Column(db.Integer, primary_key=True)</span><br><span class="line">    tags = db.relationship(&apos;Tag&apos;, secondary=tags,</span><br><span class="line">        backref=db.backref(&apos;pages&apos;, lazy=&apos;dynamic&apos;))</span><br><span class="line"></span><br><span class="line">class Tag(db.Model):</span><br><span class="line">    id = db.Column(db.Integer, primary_key=True)</span><br></pre></td></tr></table></figure></p><p>在relationship()方法传入secondary参数，其值为关联表的表名。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Simple-Example&quot;&gt;&lt;a href=&quot;#Simple-Example&quot; class=&quot;headerlink&quot; title=&quot;Simple Example&quot;&gt;&lt;/a&gt;Simple Example&lt;/h2&gt;&lt;p&gt;简单的一个例子：&lt;br&gt;&lt;figure cl
      
    
    </summary>
    
      <category term="python" scheme="http://reworth.site/categories/python/"/>
    
    
      <category term="flask" scheme="http://reworth.site/tags/flask/"/>
    
      <category term="python" scheme="http://reworth.site/tags/python/"/>
    
      <category term="sqlalchemy" scheme="http://reworth.site/tags/sqlalchemy/"/>
    
  </entry>
  
  <entry>
    <title>Jp-words-1</title>
    <link href="http://reworth.site/2018/01/04/Jp-words-1/"/>
    <id>http://reworth.site/2018/01/04/Jp-words-1/</id>
    <published>2018-01-04T09:12:51.000Z</published>
    <updated>2018-01-04T09:14:26.776Z</updated>
    
    <content type="html"><![CDATA[<p>あいそう「愛想」 讨厌，招待</p><p>間柄「あいだがら」关系</p><p>敢えて「あえて」特意，并不</p><p>あなたの将来のために、敢えて忠告「ちゅうこく」します</p><p>どうしても行きたいなら、私はあえて反対しない</p><p>浅ましい「あさましい」卑鄙</p><p>欺く「あざむく」</p><p>嘲笑う「あさわらう」</p><p>あせる「焦る、褪せる」着急</p><p>朝寝坊「あさねぼう」睡懒觉</p><p>後回し「あとまわし」推迟</p><p>彼が自分のことを後回しにしても、他の人を助けるような人だ。</p><p>あやふや  含糊</p><p>彼のあやふやな態度に、彼女は激怒「げきど」した。</p><p>過ち「あやまち」 过错</p><p>誰でも若い時は、過ちの一つや二つおかす。</p><p>あらっぽい「荒っぽい、粗っぽい」  粗野</p><p>彼はあらっぽい性格に見えますが、実は優しい人なんです。</p><p>あらかじめ「予め」 预先</p><p>あらかじめ必要なものをメモしていくと、無駄な買い物をしない。</p><p>ありのまま   老实，坦白</p><p>ありのままの私を認めてくれる人と結婚したいと思っている</p><p>案の定「あんのじょう」果然，果如所料</p><p>連休中の新幹線は、案の定、込んでいた。</p><p>いかにも  果然</p><p>いかにも、おっしゃる通りです。彼はいかにも優等生のダイプだ。</p><p>幾多「いくた」许多</p><p>父は、幾多の困難を乗り越えて、会社大きくしてきたそうだ</p><p>一括「いっかつ」 汇总。一包在内</p><p>時間がないので、三つの議案を一括して審議「しんぎ」する</p><p>意図「いと」  意图</p><p>著者のいとがよくわからない本だ</p><p>今更「いまさら」  事到如今</p><p>いまさら謝られでも、もう遲い。</p><p>いやいや「嫌々」  勉勉强强</p><p>内訳「うちわけ」  详细内容</p><p>進歩「しんぽ」     进步</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;あいそう「愛想」 讨厌，招待&lt;/p&gt;
&lt;p&gt;間柄「あいだがら」关系&lt;/p&gt;
&lt;p&gt;敢えて「あえて」特意，并不&lt;/p&gt;
&lt;p&gt;あなたの将来のために、敢えて忠告「ちゅうこく」します&lt;/p&gt;
&lt;p&gt;どうしても行きたいなら、私はあえて反対しない&lt;/p&gt;
&lt;p&gt;浅ましい「あさましい」
      
    
    </summary>
    
      <category term="japaness" scheme="http://reworth.site/categories/japaness/"/>
    
    
      <category term="japaness" scheme="http://reworth.site/tags/japaness/"/>
    
  </entry>
  
  <entry>
    <title>vagrant</title>
    <link href="http://reworth.site/2018/01/04/vagrant/"/>
    <id>http://reworth.site/2018/01/04/vagrant/</id>
    <published>2018-01-04T08:27:57.000Z</published>
    <updated>2018-01-04T08:30:09.721Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Vagrant常用命令"><a href="#Vagrant常用命令" class="headerlink" title="Vagrant常用命令"></a>Vagrant常用命令</h2><p>Vagrant Cmd：</p><ul><li><code>vagrant box add</code> 添加box的操作</li><li><code>vagrant init</code> 初始化box的操作</li><li><code>vagrant up</code> 启动虚拟机的操作</li><li><code>vagrant ssh</code> 登录虚拟机的操作</li></ul><p>Vagrant还包括如下一些操作：</p><ul><li><p><code>vagrant box list</code><br>  显示当前已经添加的box列表</p><pre><code>$ vagrant box listbase (virtualbox)</code></pre></li><li><p><code>vagrant box remove</code><br>  删除相应的box</p><pre><code>$ vagrant box remove base virtualboxRemoving box &apos;base&apos; with provider &apos;virtualbox&apos;...</code></pre></li><li><p><code>vagrant destroy</code><br>  停止当前正在运行的虚拟机并销毁所有创建的资源</p><pre><code>$ vagrant destroyAre you sure you want to destroy the &apos;default&apos; VM? [y/N] y[default] Destroying VM and associated drives...</code></pre></li><li><p><code>vagrant halt</code>  </p><p>  关机</p><pre><code>$ vagrant halt[default] Attempting graceful shutdown of VM...</code></pre></li><li><p><code>vagrant package</code></p><p>  打包命令，可以把当前的运行的虚拟机环境进行打包</p><pre><code>$ vagrant package[default] Attempting graceful shutdown of VM...[default] Clearing any previously set forwarded ports...[default] Creating temporary directory for export...[default] Exporting VM...[default] Compressing package to: /Users/astaxie/vagrant/package.box</code></pre></li><li><p><code>vagrant plugin</code></p><p>  用于安装卸载插件</p></li><li><p><code>vagrant provision</code></p><p>  通常情况下Box只做最基本的设置，而不是设置好所有的环境，因此Vagrant通常使用Chef或者Puppet来做进一步的环境搭建。那么Chef或者Puppet称为provisioning，而该命令就是指定开启相应的provisioning。按照Vagrant作者的说法，所谓的provisioning就是”The problem of installing software on a booted system”的意思。除了Chef和Puppet这些主流的配置管理工具之外，我们还可以使用Shell来编写安装脚本。</p><p>  例如： <code>vagrant provision --provision-with chef</code></p></li><li><p><code>vagrant reload</code>  </p><p>  重新启动虚拟机，主要用于重新载入配置文件</p><pre><code>$ vagrant reload[default] Attempting graceful shutdown of VM...[default] Setting the name of the VM...[default] Clearing any previously set forwarded ports...[default] Creating shared folders metadata...[default] Clearing any previously set network interfaces...[default] Preparing network interfaces based on configuration...[default] Forwarding ports...[default] -- 22 =&gt; 2222 (adapter 1)[default] Booting VM...[default] Waiting for VM to boot. This can take a few minutes.[default] VM booted and ready for use![default] Setting hostname...[default] Mounting shared folders...[default] -- /vagrant</code></pre></li><li><p><code>vagrant resume</code></p><p>  恢复前面被挂起的状态</p><pre><code>$vagrant resume[default] Resuming suspended VM...[default] Booting VM...[default] Waiting for VM to boot. This can take a few minutes.[default] VM booted and ready for use!</code></pre></li><li><p><code>vagrant ssh-config</code></p><p>  输出用于ssh连接的一些信息</p><pre><code>$vagrant ssh-configHost default  HostName 127.0.0.1  User vagrant  Port 2222  UserKnownHostsFile /dev/null  StrictHostKeyChecking no  PasswordAuthentication no  IdentityFile &quot;/Users/astaxie/.vagrant.d/insecure_private_key&quot;  IdentitiesOnly yes  LogLevel FATAL</code></pre></li><li><p><code>vagrant status</code></p><p>  获取当前虚拟机的状态</p><pre><code>$vagrant statusCurrent machine states:default                   running (virtualbox)The VM is running. To stop this VM, you can run `vagrant halt` toshut it down forcefully, or you can run `vagrant suspend` to simplysuspend the virtual machine. In either case, to restart it again,simply run `vagrant up`.</code></pre></li><li><p><code>vagrant suspend</code></p><p>  挂起当前的虚拟机</p><pre><code>$ vagrant suspend[default] Saving VM state and suspending execution...</code></pre></li></ul><h2 id="模拟打造多机器的分布式系统"><a href="#模拟打造多机器的分布式系统" class="headerlink" title="模拟打造多机器的分布式系统"></a>模拟打造多机器的分布式系统</h2><p>前面这些单主机单虚拟机主要是用来自己做开发机，从这部分开始的内容主要将向大家介绍如何在单机上通过虚拟机来打造分布式造集群系统。这种多机器模式特别适合以下几种人：</p><ol><li>快速建立产品网络的多机器环境，例如web服务器、db服务器</li><li>建立一个分布式系统，学习他们是如何交互的</li><li>测试API和其他组件的通信</li><li>容灾模拟，网络断网、机器死机、连接超时等情况</li></ol><p>Vagrant支持单机模拟多台机器，而且支持一个配置文件Vagrntfile就可以跑分布式系统。</p><p>现在我们来建立多台VM跑起來，並且让他们之间能够相通信，假设一台是应用服务器、一台是DB服务器，那么这个结构在Vagrant中非常简单，其实和单台的配置差不多，你只需要通过<code>config.vm.define</code>来定义不同的角色就可以了，现在我们打开配置文件进行如下设置：</p><pre><code>Vagrant.configure(&quot;2&quot;) do |config|  config.vm.define :web do |web|    web.vm.provider &quot;virtualbox&quot; do |v|          v.customize [&quot;modifyvm&quot;, :id, &quot;--name&quot;, &quot;web&quot;, &quot;--memory&quot;, &quot;512&quot;]    end    web.vm.box = &quot;base&quot;    web.vm.hostname = &quot;web&quot;    web.vm.network :private_network, ip: &quot;11.11.1.1&quot;  end  config.vm.define :db do |db|    db.vm.provider &quot;virtualbox&quot; do |v|          v.customize [&quot;modifyvm&quot;, :id, &quot;--name&quot;, &quot;db&quot;, &quot;--memory&quot;, &quot;512&quot;]    end    db.vm.box = &quot;base&quot;    db.vm.hostname = &quot;db&quot;    db.vm.network :private_network, ip: &quot;11.11.1.2&quot;  endend</code></pre><p>这里的设置和前面我们单机设置配置类似，只是我们使用了<code>:web</code>以及<code>:db</code>分別做了两个VM的设置，并且给每个VM设置了不同的<code>hostname</code>和IP，设置好之后再使用<code>vagrant up</code>将虚拟机跑起来：</p><pre><code>$ vagrant upBringing machine &apos;web&apos; up with &apos;virtualbox&apos; provider...Bringing machine &apos;db&apos; up with &apos;virtualbox&apos; provider...[web] Setting the name of the VM...[web] Clearing any previously set forwarded ports...[web] Creating shared folders metadata...[web] Clearing any previously set network interfaces...[web] Preparing network interfaces based on configuration...[web] Forwarding ports...[web] -- 22 =&gt; 2222 (adapter 1)[web] Running any VM customizations...[web] Booting VM...[web] Waiting for VM to boot. This can take a few minutes.[web] VM booted and ready for use![web] Setting hostname...[web] Configuring and enabling network interfaces...[web] Mounting shared folders...[web] -- /vagrant[db] Setting the name of the VM...[db] Clearing any previously set forwarded ports...[db] Fixed port collision for 22 =&gt; 2222. Now on port 2200.[db] Creating shared folders metadata...[db] Clearing any previously set network interfaces...[db] Preparing network interfaces based on configuration...[db] Forwarding ports...[db] -- 22 =&gt; 2200 (adapter 1)[db] Running any VM customizations...[db] Booting VM...[db] Waiting for VM to boot. This can take a few minutes.[db] VM booted and ready for use![db] Setting hostname...[db] Configuring and enabling network interfaces...[db] Mounting shared folders...[db] -- /vagrant</code></pre><p>看到上面的信息输出后，我们就可以通过<code>vagrant ssh</code>登录虚拟机了，但是这次和上次使用的不一样了，这次我们需要指定相应的角色，用来告诉ssh你期望连接的是哪一台：</p><pre><code>$ vagrant ssh webvagrant@web:~$$ vagrant ssh dbvagrant@db:~$</code></pre><p>是不是很酷！现在接下来我们再来验证一下虚拟机之间的通信，让我们先使用ssh登录web虚拟机，然后在web虚拟机上使用ssh登录db虚拟机(默认密码是<code>vagrant</code>)：</p><pre><code>$ vagrant ssh webLinux web 2.6.32-38-server #83-Ubuntu SMP Wed Jan 4 11:26:59 UTC 2012 x86_64 GNU/LinuxUbuntu 10.04.4 LTSWelcome to the Ubuntu Server! * Documentation:  http://www.ubuntu.com/server/docNew release &apos;precise&apos; available.Run &apos;do-release-upgrade&apos; to upgrade to it.Welcome to your Vagrant-built virtual machine.Last login: Thu Aug  8 18:55:44 2013 from 10.0.2.2vagrant@web:~$ ssh 11.11.1.2The authenticity of host &apos;11.11.1.2 (11.11.1.2)&apos; can&apos;t be established.RSA key fingerprint is e7:8f:07:57:69:08:6e:fa:82:bc:1c:f6:53:3f:12:9e.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added &apos;11.11.1.2&apos; (RSA) to the list of known hosts.vagrant@11.11.1.2&apos;s password:Linux db 2.6.32-38-server #83-Ubuntu SMP Wed Jan 4 11:26:59 UTC 2012 x86_64 GNU/LinuxUbuntu 10.04.4 LTSWelcome to the Ubuntu Server! * Documentation:  http://www.ubuntu.com/server/docNew release &apos;precise&apos; available.Run &apos;do-release-upgrade&apos; to upgrade to it.Welcome to your Vagrant-built virtual machine.Last login: Thu Aug  8 18:58:50 2013 from 10.0.2.2vagrant@db:~$</code></pre><p>通过上面的信息我们可以看到虚拟机之间通信是畅通的，所以现在开始你伟大的架构设计吧，你想设计怎么样的架构都可以，唯一限制你的就是你主机的硬件配置了。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Vagrant常用命令&quot;&gt;&lt;a href=&quot;#Vagrant常用命令&quot; class=&quot;headerlink&quot; title=&quot;Vagrant常用命令&quot;&gt;&lt;/a&gt;Vagrant常用命令&lt;/h2&gt;&lt;p&gt;Vagrant Cmd：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;va
      
    
    </summary>
    
      <category term="vagrant" scheme="http://reworth.site/categories/vagrant/"/>
    
    
      <category term="vagrant" scheme="http://reworth.site/tags/vagrant/"/>
    
  </entry>
  
  <entry>
    <title>hexo cmd</title>
    <link href="http://reworth.site/2018/01/03/hexo-cmd/"/>
    <id>http://reworth.site/2018/01/03/hexo-cmd/</id>
    <published>2018-01-03T11:56:46.000Z</published>
    <updated>2018-01-03T12:00:30.402Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Hexo-Cmd"><a href="#Hexo-Cmd" class="headerlink" title="Hexo Cmd"></a>Hexo Cmd</h1><blockquote><p>hexo help  # 查看帮助<br>hexo version  #查看Hexo的版本<br>hexo algolia  # 更新search庫<br>hexo new “postName” #新建文章<br>hexo new post “title”  # 生成新文章：\source_posts\title.md，可省略post<br>hexo new page “pageName” #新建页面<br>hexo clean #清除部署緩存<br>hexo n == hexo new #新建文章<br>hexo g == hexo generate #生成静态页面至public目录<br>hexo s == hexo server #开启预览访问端口（默认端口4000，’ctrl + c’关闭server）<br>hexo d == hexo deploy #将.deploy目录部署到GitHub<br>hexo d -g #生成加部署<br>hexo s -g #生成加预览</p></blockquote><h1 id="Clean-amp-Update"><a href="#Clean-amp-Update" class="headerlink" title="Clean&amp;Update"></a>Clean&amp;Update</h1><pre><code>hexo clhexo d -g</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Hexo-Cmd&quot;&gt;&lt;a href=&quot;#Hexo-Cmd&quot; class=&quot;headerlink&quot; title=&quot;Hexo Cmd&quot;&gt;&lt;/a&gt;Hexo Cmd&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;hexo help  # 查看帮助&lt;br&gt;hexo version
      
    
    </summary>
    
      <category term="hexo" scheme="http://reworth.site/categories/hexo/"/>
    
    
      <category term="hexo" scheme="http://reworth.site/tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>flask definitions</title>
    <link href="http://reworth.site/2018/01/03/flask-definitions/"/>
    <id>http://reworth.site/2018/01/03/flask-definitions/</id>
    <published>2018-01-03T11:16:42.000Z</published>
    <updated>2018-01-03T11:45:22.865Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Flask’s-some-definitions"><a href="#Flask’s-some-definitions" class="headerlink" title="Flask’s some definitions"></a>Flask’s some definitions</h1><ul><li>WSGI: Web服务器网关接口，是一种Web服务使用的协议</li><li>路由: 处理URL和函数之间关系的程序称为”路由”</li><li>视图函数: 类似于index()这样的，被app.route装饰器注册为路由的函数，或者通过app.add_url_rule()添加路由映射关系的函数，被称为视图函数。  </li><li>app.route(): 路由装饰器，可以带参数，参数可以指定数据类型：int/float/path。path类似于字符串，但不将反斜线/当做分隔符。 </li></ul><h1 id="Flask上下文全局变量"><a href="#Flask上下文全局变量" class="headerlink" title="Flask上下文全局变量"></a>Flask上下文全局变量</h1><ul><li>current_app: 程序上下文，当前激活程序的程序实例，所有线程公用一个该实例。 </li><li>g: 程序上下文，处理请求时用作临时存储的对象，每次请求都会重设这个变量</li><li>request: 请求上下文，请求对象，封装了客户端发出的 HTTP 请求中的内容，不同线程之间互不干扰</li><li>session: 请求上下问，用户会话，用于存储请求之间需要“记住”的值的词典。 </li></ul><h1 id="Flask支持的4种钩子函数"><a href="#Flask支持的4种钩子函数" class="headerlink" title="Flask支持的4种钩子函数"></a>Flask支持的4种钩子函数</h1><ul><li>before_first_request: 注册一个函数，在处理第一个请求之前运行。 </li><li>before_request: 注册一个函数，在每次请求之前运行。</li><li>after_request: 注册一个函数，如果没有未处理的异常抛出，在每次请求之后运行。</li><li>teardown_request:注册一个函数，即使有未处理的异常抛出，也在每次请求之后运行。</li></ul><h1 id="Jinja2模板使用"><a href="#Jinja2模板使用" class="headerlink" title="Jinja2模板使用"></a>Jinja2模板使用</h1><p>渲染模板: render_template(“user.html”, name=name)<br>控制结构：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#123;% if user %&#125; </span><br><span class="line">      Hello, &#123;&#123; user &#125;&#125;! </span><br><span class="line">    &#123;% else %&#125; </span><br><span class="line">      Hello, Stranger! </span><br><span class="line">    &#123;% endif %&#125;</span><br><span class="line"></span><br><span class="line">    &lt;ul&gt; </span><br><span class="line">    &#123;% for comment in comments %&#125; </span><br><span class="line">      &lt;li&gt;&#123;&#123; comment &#125;&#125;&lt;/li&gt;  </span><br><span class="line">       &#123;% endfor %&#125; </span><br><span class="line">    &lt;/ul&gt;</span><br></pre></td></tr></table></figure></p><p>宏-类似于函数:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"> &#123;% macro render_comment(comment) %&#125; </span><br><span class="line">   &lt;li&gt;&#123;&#123; comment &#125;&#125;&lt;/li&gt; </span><br><span class="line"> &#123;% endmacro %&#125; </span><br><span class="line"> </span><br><span class="line"> &lt;ul&gt; </span><br><span class="line"> &#123;% for comment in comments %&#125; </span><br><span class="line">   &#123;&#123; render_comment(comment) &#125;&#125; </span><br><span class="line"> &#123;% endfor %&#125; </span><br><span class="line">&lt;/ul&gt;</span><br></pre></td></tr></table></figure></p><h1 id="Jinja2变量过滤器"><a href="#Jinja2变量过滤器" class="headerlink" title="Jinja2变量过滤器"></a>Jinja2变量过滤器</h1><blockquote><p># safe: 渲染值时不转义<br># capitalize: 把值的首字母转换成大写，其他字母转换成小写<br># lower: 把值转换成小写形式<br># upper: 把值转换成大写形式<br># title: 把值中每个单词的首字母都转换成大写<br># trim: 把值的首尾空格去掉<br># striptags: 渲染之前把值中所有的 HTML 标签都删掉 </p></blockquote><h1 id="WTForms支持的字段"><a href="#WTForms支持的字段" class="headerlink" title="WTForms支持的字段"></a>WTForms支持的字段</h1><p><strong>注意添加app.config[‘SECRET_KEY’] = ‘hard to guess string’</strong></p><ul><li>StringField 文本字段 </li><li>TextAreaField 多行文本字段 </li><li>PasswordField 密码文本字段 </li><li>HiddenField 隐藏文本字段 </li><li>DateField 值为datatime.data格式的文本字段 </li><li>DateTimeField 值为datatime.datatime格式的文本字段 </li><li>DecimalField 值为decimal.Decimal格式的文本字段 </li><li>IntegerField 值为整数的文本字段 </li><li>FloatField 值为浮点数的文本字段 </li><li>BooleanField 值为True或False的复选框 </li><li>RadioField 一组单选框 </li><li>SelectField 值唯一的下拉列表 </li><li>SelectMultipleField 可选多个值得下拉列表 </li><li>FileField 文件上传字段 </li><li>SubmitField 表单提交按钮 </li><li>FormField 把表单作为字段嵌入另一个表单 </li><li>FieldList 一组指定类型的字段 </li></ul><h1 id="常见返回码"><a href="#常见返回码" class="headerlink" title="常见返回码"></a>常见返回码</h1><p>200 OK - [GET]：服务器成功返回用户请求的数据<br>201 CREATED - [POST/PUT/PATCH]：用户新建或修改数据成功<br>202 Accepted - [<em>]：表示一个请求已经进入后台排队（异步任务）<br>204 NO CONTENT - [DELETE]：用户删除数据成功<br>400 INVALID REQUEST - [POST/PUT/PATCH]：用户发出的请求有错误，服务器没有进行新建或修改数据的操作<br>401 Unauthorized - [</em>]：表示用户没有权限（令牌、用户名、密码错误）<br>403 Forbidden - [<em>] 表示用户得到授权（与401错误相对），但是访问是被禁止的<br>404 NOT FOUND - [</em>]：用户发出的请求针对的是不存在的记录，服务器没有进行操作<br>406 Not Acceptable - [GET]：用户请求的格式不可得<br>410 Gone -[GET]：用户请求的资源被永久删除，且不会再得到的<br>422 Unprocesable entity - [POST/PUT/PATCH] 当创建一个对象时，发生一个验证错误<br>500 INTERNAL SERVER ERROR - [*]：服务器发生错误，用户将无法判断发出的请求是否成功 </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Flask’s-some-definitions&quot;&gt;&lt;a href=&quot;#Flask’s-some-definitions&quot; class=&quot;headerlink&quot; title=&quot;Flask’s some definitions&quot;&gt;&lt;/a&gt;Flask’s some d
      
    
    </summary>
    
      <category term="flask" scheme="http://reworth.site/categories/flask/"/>
    
    
      <category term="flask" scheme="http://reworth.site/tags/flask/"/>
    
      <category term="python" scheme="http://reworth.site/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>sed-grep</title>
    <link href="http://reworth.site/2018/01/01/sed-grep/"/>
    <id>http://reworth.site/2018/01/01/sed-grep/</id>
    <published>2018-01-01T09:20:47.000Z</published>
    <updated>2018-01-01T09:34:25.346Z</updated>
    
    <content type="html"><![CDATA[<h2 id="sed"><a href="#sed" class="headerlink" title="sed"></a>sed</h2><p>sed对文本的处理非常的强大，并且sed非常小，操作跟awk类似。sed是按顺序逐行进行读取文件。然后，它执行的是该行指定的所有操作，并在完成请求的修改之后的内容显示出来，也可以将其存放到文件之中。</p><h2 id="sed-nefri-动作"><a href="#sed-nefri-动作" class="headerlink" title="sed  [-nefri] [动作]"></a>sed  [-nefri] [动作]</h2><ul><li>-n ：使用安静(silent)模式。在一般 sed 的用法中，所有来自 STDIN 的数据一般都会被列出到终端上。但如果加上 -n 参数后，则只有经过sed 特殊处理的那一行(或者动作)才会被列出来。</li><li>-e ：直接在命令列模式上进行 sed 的动作编辑；</li><li>-f ：直接将 sed 的动作写在一个文件内， -f filename 则可以运行 filename 内的 sed 动作；</li><li>-r ：sed 的动作支持的是延伸型正规表示法的语法。(默认是基础正规表示法语法)</li><li>-i ：直接修改读取的文件内容，而不是输出到终端。</li><li>–follow-symlinks    直接修改文件时跟随软链接</li></ul><p><strong>动作说明</strong> ： [n1[,n2]]fuction<br>n1, n2 ：不见得会存在，一般代表『选择进行动作的行数』，举例来说，如果我的动作是需要在 10 到 20 行之间进行的，则『 10,20[动作行为] 』<br> <strong>funtion</strong>：</p><ul><li>a ：新增， a 的后面可以接字串，而这些字串会在新的一行出现(目前的下一行)～</li><li>c ：取代， c 的后面可以接字串，这些字串可以取代 n1,n2 之间的行！</li><li>d ：删除，因为是删除啊，所以 d 后面通常不接任何咚咚；</li><li>i ：插入， i 的后面可以接字串，而这些字串会在新的一行出现(目前的上一行)；</li><li>p ：列印，亦即将某个选择的数据印出。通常 p 会与参数 sed -n 一起运行～</li><li>s ：取代，可以直接进行取代的工作哩！通常这个 s 的动作可以搭配正规表示法！例如 1,20s/old/new/g 就是啦！</li></ul><h2 id="grep"><a href="#grep" class="headerlink" title="grep"></a>grep</h2><p><strong>命令格式</strong>： grep [option] pattern file</p><h2 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h2><ul><li>-i：忽略大小写</li><li>-c：打印匹配的行数</li><li>-v：查找不包含匹配项的行</li><li>-n：打印包含匹配项的行和行标</li></ul><h2 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h2><blockquote><p>^  #锚定行的开始 如：’^grep’匹配所有以grep开头的行。<br>$  #锚定行的结束 如：’grep$’匹配所有以grep结尾的行。<br>.  #匹配一个非换行符的字符 如：’gr.p’匹配gr后接一个任意字符，然后是p。<br>*  #匹配零个或多个先前字符 如：’<em>grep’匹配所有一个或多个空格后紧跟grep的行。<br>.</em>   #一起用代表任意字符。<br>[]   #匹配一个指定范围内的字符，如’[Gg]rep’匹配Grep和grep。<br>[^]  #匹配一个不在指定范围内的字符，如：’[^A-FH-Z]rep’匹配不包含A-R和T-Z的一个字母开头，紧跟rep的行。<br>(..)  #标记匹配字符，如’(love)‘，love被标记为1。<br>\&lt;      #锚定单词的开始，如:’\<grep'匹配包含以grep开头的单词的行。 \="">      #锚定单词的结束，如'grep\>‘匹配包含以grep结尾的单词的行。<br>x{m}  #重复字符x，m次，如：’0{5}‘匹配包含5个o的行。<br>x{m,}  #重复字符x,至少m次，如：’o{5,}‘匹配至少有5个o的行。<br>x{m,n}  #重复字符x，至少m次，不多于n次，如：’o{5,10}‘匹配5–10个o的行。<br>\w    #匹配文字和数字字符，也就是[A-Za-z0-9]，如：’G\w*p’匹配以G后跟零个或多个文字或数字字符，然后是p。<br>\W    #\w的反置形式，匹配一个或多个非单词字符，如点号句号等。   </grep'匹配包含以grep开头的单词的行。></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;sed&quot;&gt;&lt;a href=&quot;#sed&quot; class=&quot;headerlink&quot; title=&quot;sed&quot;&gt;&lt;/a&gt;sed&lt;/h2&gt;&lt;p&gt;sed对文本的处理非常的强大，并且sed非常小，操作跟awk类似。sed是按顺序逐行进行读取文件。然后，它执行的是该行指定的所有操作
      
    
    </summary>
    
      <category term="linux" scheme="http://reworth.site/categories/linux/"/>
    
    
      <category term="sed" scheme="http://reworth.site/tags/sed/"/>
    
      <category term="grep" scheme="http://reworth.site/tags/grep/"/>
    
  </entry>
  
  <entry>
    <title>awk</title>
    <link href="http://reworth.site/2017/12/29/awk/"/>
    <id>http://reworth.site/2017/12/29/awk/</id>
    <published>2017-12-29T10:00:59.000Z</published>
    <updated>2017-12-29T10:43:12.447Z</updated>
    
    <content type="html"><![CDATA[<h2 id="awk"><a href="#awk" class="headerlink" title="awk"></a>awk</h2><p><strong>awk</strong>是一种处理文本的语言，是一个强大的文本分析工具，awk是以列为划分记数的，$0表示所有列，$1表示第一列，$2表示第二列。</p><h2 id="awk常用参数"><a href="#awk常用参数" class="headerlink" title="awk常用参数"></a>awk常用参数</h2><ul><li>-F指定输入文件分隔符，如-F：</li><li>-v 赋值一个用户定义变量，如-va=1</li><li>-f 从脚本文件中读取awk命令</li></ul><h2 id="多个分隔符"><a href="#多个分隔符" class="headerlink" title="多个分隔符"></a>多个分隔符</h2><p><code>awk -F &#39;[-|]&#39; &#39;{print $3}&#39; data</code><br>上面这个例子是以-和|为分隔符进行分割。</p><h2 id="设置变量"><a href="#设置变量" class="headerlink" title="设置变量"></a>设置变量</h2><p>设置awk自定义变量，使用参数-v<br><code>cat data.txt | awk -v a=9 &#39;{print $1,$1+a}&#39;</code><br>如上，设置了变量a的值，在输出的时候添加一个$1+a的值。<br>如果在脚本中使用的时候，前面已经定义了一个$2的变量，并且你就是像要使用这个变量的话，就要使用以下的形式：<br><code>awk &#39;{print $$2}&#39;</code></p><h2 id="逻辑判断"><a href="#逻辑判断" class="headerlink" title="逻辑判断"></a>逻辑判断</h2><p><code>cat data.txt | awk &#39;$1==&quot;reworth&quot; {print}</code><br>输出第一列为reworth的所有行。<br><code>cat data.txt | awk &#39;$1!=&quot;reworth&quot; {print}&#39;</code><br>输出第一列不是reworth的所有行。</p><h2 id="正则匹配"><a href="#正则匹配" class="headerlink" title="正则匹配"></a>正则匹配</h2><p><code>cat data.txt | awk &#39;$2 ~ /reworth.*/ {print}&#39;</code><br>匹配第二列中以reworth开头的所有行。对某列进行匹配时需要在列之后加个～表示进行匹配。<br><code>cat data.txt | awk &#39;/reworth.*/ {print}&#39;</code><br>匹配以reworth开头的所有行。<br><strong>匹配取反</strong> !~<br><code>cat data.txt | awk &#39;$2 !~ /reworth/ {print}&#39;</code><br>匹配第二列不是reworth的所有行。</p><h2 id="内置变量"><a href="#内置变量" class="headerlink" title="内置变量"></a>内置变量</h2><ul><li>FILENAME : 当前输入文件名称</li><li>NF : 当前输入行的字段编号</li><li>OFS : 输出字段分隔符</li><li>NR : 当前输入行编号(是指输入行 1，2，3……等)</li><li>FS : 输入字段分隔符</li><li>ORS : 输出记录分隔符</li><li>RS : 输入记录分隔符</li></ul><h2 id="内置函数"><a href="#内置函数" class="headerlink" title="内置函数"></a>内置函数</h2><p><strong>substr字符串截取</strong><br><code>cat data.txt | awk &#39;{print substr($1,1,4)}&#39;</code><br>截取第一列中的第一个到第四个字符。<br><strong>split 切片</strong><br><code>cat data.txt |awk &#39;{split($1,a,&quot;,&quot;);print a[1],a[2],a[3]}&#39;</code><br>以逗号分隔第一列，并输出分隔后的数据。<br><strong>gsub 替换</strong><br><code>cat data.txt | awk &#39;&#39;{gsub(&quot;abc&quot;,&quot;asd&quot;,$2);print}</code><br>将第二列中的abc替换成asd</p><h2 id="统计"><a href="#统计" class="headerlink" title="统计"></a>统计</h2><blockquote><p>grep ‘tower_activity_op’ /data/s*/log/test.log  | awk -F’[=,]’ ‘{a[$2] -= $12; b[$2] -= $14; item_count[$2]++;} END{for(i in a) {serverid=i;  cmd=”/usr/bin/mysql -u root -h \”192.168.0.1\” -p1234 -D stat -e \”replace into test(date,uid,cash,coins,number,code,serverid) values(\047’$Date’\047,”i”,”a[i]”,”b[i]”,”item_count[i]”,\047测试\047,”serverid”)\””; system(cmd);}}’ </p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;awk&quot;&gt;&lt;a href=&quot;#awk&quot; class=&quot;headerlink&quot; title=&quot;awk&quot;&gt;&lt;/a&gt;awk&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;awk&lt;/strong&gt;是一种处理文本的语言，是一个强大的文本分析工具，awk是以列为划分记数的，$0表示所有列，$
      
    
    </summary>
    
      <category term="linux" scheme="http://reworth.site/categories/linux/"/>
    
    
      <category term="awk" scheme="http://reworth.site/tags/awk/"/>
    
  </entry>
  
  <entry>
    <title>volume-container</title>
    <link href="http://reworth.site/2017/12/28/volume-container/"/>
    <id>http://reworth.site/2017/12/28/volume-container/</id>
    <published>2017-12-28T11:00:24.000Z</published>
    <updated>2017-12-29T07:03:58.446Z</updated>
    
    <content type="html"><![CDATA[<p>volume container是专门为其他容器提供volume的容器。它提供的卷可以是bind mount,<br>也可以是docker managed volume.下面我创建一个volume container:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker create --name vc_data \</span><br><span class="line">-v ~/htdocs:/usr/local/apache2/htdocs \</span><br><span class="line">-v ~/other/useful/tools \</span><br><span class="line">busybox</span><br></pre></td></tr></table></figure></p><p>我们将容器命名为vc_data.注意这里执行的是docker create命令，这是因为volume container<br>的作用是只提供数据，它本身不需要处于运行状态。容器中mount了两个volume:</p><ul><li>bind mount,存放web server的静态文件。</li><li>docker managed volume,存放一些实用的工具<br>通过docker inspect可以查看这两个volume</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;volume container是专门为其他容器提供volume的容器。它提供的卷可以是bind mount,&lt;br&gt;也可以是docker managed volume.下面我创建一个volume container:&lt;br&gt;&lt;figure class=&quot;highlight
      
    
    </summary>
    
      <category term="docker" scheme="http://reworth.site/categories/docker/"/>
    
    
      <category term="volume" scheme="http://reworth.site/tags/volume/"/>
    
  </entry>
  
</feed>
